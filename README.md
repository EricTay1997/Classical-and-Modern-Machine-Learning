# Classical-and-Modern-Machine-Learning
I am currently exploring a career pivot into Machine Learning roles. This repository will be used to help me consolidate my knowledge.

Broadly, this repository will include: 
* Notes on various topics (Edit: For some reason, markdown on Github isn't formatting the same as PyCharm)
  * Classical ML/Statistics
    * Linear Algebra and Calculus
    * Probability and Information Theory
    * Bayesian Statistics
    * Statistical Learning Theory
    * Statistical Testing and Metrics
    * Linear Regression & Regularization
    * Naive Bayes & Logistic Regression
    * GLMs
    * SVMs
    * Decision Trees
    * Ensemble Learning, Random Forests and Boosting
    * Dimensionality Reduction
    * K-means
    * Gaussian Mixtures and EM
    * Causal Inference
  * Modern ML (Note that the delineation is not super clear here and this separation is purely made for organizational purposes)
    * Concepts Around Training DNNs
    * Practical Considerations
    * AI Safety
    * MLP
    * CNN Architectures
    * Autoencoders
    * GANs
    * Diffusion Models
    * Normalizing Flows
    * RNNs & LSTMs
    * Attention & Transformers
    * Modern LLMs
    * Reinforcement Learning
    * Applied AI
* Code implementation for various algorithms, which may either be implemented from scratch or copied. Any copied code will only be included after thorough understanding.
  * The first priority would be to get implementations that work.
  * If time permits, a stretch goal would be to refactor the code with a greater emphasis on OOP, e.g. [John's repo](https://github.com/johnma2006/candle/tree/main)
  * Other projects in my Github included projects from college where I implemented different ML models. These models should all be included in this repo. 
  * I want to emphasize that the goal of these implementations would be to ensure that I have a thorough understanding of topics, rather than being the most involved projects. Notebooks may be more sparse if I believe my understanding to be sufficient.
* Exercises for practice

I shall try to be diligent in citing my sources. Due to visa-related time constraints, I do apologize for any lapses in citation. At the current moment, I envision pulling most heavily from the following sources:
* [Hands-On Machine Learning by Aurélien Géron](https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1098125975)
* [Dive into Deep Learning by Zhang, Lipton, Li and Smola](http://d2l.ai)
* [Deep Learning by Goodfellow, Bengio and Courville](https://www.deeplearningbook.org)
* [Implementations of Various LLMs by Ma](https://github.com/johnma2006/candle)
* [Distill](https://distill.pub)
* [Lilian Weng's Blog](https://lilianweng.github.io)
* [Christopher Olah's Blog](https://colah.github.io/about.html)
