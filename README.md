# A Broad Review of Classical and Modern ML Algorithms
This repository will be used to help me consolidate my knowledge regarding various ML topics.

This repository will include: 
* Notes on various topics (Edit: For some reason, markdown on Github isn't formatting the same as PyCharm)
  * Classical ML/Statistics
    * Linear Algebra and Calculus
    * Probability and Information Theory
    * Statistical Learning Theory
    * Statistical Testing and Metrics
    * Bayesian Statistics
    * Linear Regression & Regularization
    * Naive Bayes & Logistic Regression & GLMs
    * SVMs
    * Decision Trees
    * Ensemble Learning, Random Forests and Boosting
    * Dimensionality Reduction
    * K-means
    * Gaussian Mixtures and EM
    * Gaussian Process
    * Causal Inference
  * Modern ML (Note that the delineation is not super clear here and this separation is purely made for organizational purposes)
    * Concepts Around Training DNNs
    * Practical Considerations
    * AI Safety
    * MLP
    * CNN Architectures
    * Autoencoders
    * GANs
    * Diffusion Models
    * Normalizing Flows
    * RNNs & LSTMs
    * Attention & Transformers
    * Modern LLMs
    * Reinforcement Learning
    * Applied AI
* Code implementation for various algorithms, which will mostly come from online resources/tutorials. 
  * The first priority would be to get implementations that work.
  * If time permits, a stretch goal would be to refactor the code with a greater emphasis on OOP, e.g. [John's repo](https://github.com/johnma2006/candle/tree/main)
  * I want to emphasize that the goal of these implementations would be to ensure that I have a thorough understanding of topics, rather than being the most involved projects. Notebooks may be more sparse if I believe my understanding to be sufficient.
* Interview Preparation

I shall try to be diligent in citing my sources. Due to visa-related time constraints, I do apologize for any lapses in citation. At the current moment, I envision pulling most heavily from the following sources:
* Notes / Code from classes I took at Duke.
* [Hands-On Machine Learning by Aurélien Géron](https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1098125975)
* [UvA Deep Learning Tutorials by Lippe](https://uvadlc-notebooks.readthedocs.io/en/latest/)
* [Dive into Deep Learning by Zhang, Lipton, Li and Smola](http://d2l.ai)
* Hugging Face Courses ([NLP](https://huggingface.co/learn/nlp-course/en/chapter1/1), [Diffusion](https://huggingface.co/learn/diffusion-course/unit0/1))
* [Build a Large Language Model (From Scratch) by Raschka](https://www.amazon.com/Build-Large-Language-Model-Scratch/dp/1633437167)
* [Deep Learning by Goodfellow, Bengio and Courville](https://www.deeplearningbook.org)
* [Implementations of Various LLMs by Ma](https://github.com/johnma2006/candle)
* [Designing Machine Learning Systems by Huyen](https://www.amazon.com/Designing-Machine-Learning-Systems-Production-Ready/dp/1098107969)
* [Machine Learning System Design Interview by Aminian and Xu](https://bytebytego.com/intro/machine-learning-system-design-interview)
* [Machine Learning System Design Interview by Pham](https://www.amazon.com/Machine-Learning-Design-Interview-System/dp/B09YQWX59Z)
* [System Design Interview by Xu](https://www.amazon.com/System-Design-Interview-insiders-Second/dp/B08CMF2CQF)
* [Distill](https://distill.pub)
* [Lilian Weng's Blog](https://lilianweng.github.io)
* [Christopher Olah's Blog](https://colah.github.io/about.html)
