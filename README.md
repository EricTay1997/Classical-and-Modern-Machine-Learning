# Classical-and-Modern-Machine-Learning
I am currently exploring a career pivot into Machine Learning roles. This repository will be used to help me consolidate my knowledge.

Broadly, this repository will include: 
* Notes on various topics
  * Classical ML
    * Basic Probability and Statistics
    * Bayesian Statistics
    * Performance Metrics
    * Linear Regression & Regularization
    * Naive Bayes & Logistic Regression
    * GLMs
    * Decision Trees
    * Ensemble Learning, Random Forests and Boosting
    * Dimensionality Reduction
    * K-means
    * Gaussian Mixtures and EM
  * Modern ML (Note that the delineation is not super clear here and this separation is purely made for organizational purposes
    * Training
    * Practical Considerations
    * AI Safety
    * MLP
    * CNN Architectures
    * Autoencoders
    * GANs
    * Diffusion Models
    * Normalizing Flows
    * RNNs & LSTMs
    * Attention & Transformers
    * Modern LLMs
    * Reinforcement Learning
    * Applied AI
* Code implementation for various algorithms, which may either be implemented from scratch or copied. Any copied code will only be included after thorough understanding.
  * The first priority would be to get implementations that work.
  * If time permits, a stretch goal would be to refactor the code appropriately, e.g. [(John's repo)]([experiments/nlp_experiments/3.3%20Chat%20with%20Mixtral%20(fine-tuned).ipynb](https://github.com/johnma2006/candle/tree/main))
  * Other projects in my Github included projects from college where I implemented different ML models. These models should all be included in this repo. 
* Exercises for practice
