# Alignment

- [Constitutional AI: Harmlessness from AI Feedback](https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback)
  - Takeaways
- [Alignment faking in large language models](https://www.anthropic.com/news/alignment-faking)
  - Takeaways
- [Studying Large Language Model Generalization with Influence Functions](https://www.anthropic.com/news/studying-large-language-model-generalization-with-influence-functions)
  - Takeaways
- [Debating with More Persuasive LLMs Leads to More Truthful Answers](https://raw.githubusercontent.com/ucl-dark/llm_debate/main/paper.pdf)
  - Takeaways
- [Many-shot jailbreaking](https://www.anthropic.com/research/many-shot-jailbreaking)
  - Takeaways